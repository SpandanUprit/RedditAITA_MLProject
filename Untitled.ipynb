{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bab75c-c70d-43e0-93fa-5b84ff6b13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0'\n",
    "]\n",
    "\n",
    "scrape_configs = [\n",
    "    {'sort': 'top', 't': 'all'},      \n",
    "    {'sort': 'top', 't': 'year'},\n",
    "    {'sort': 'controversial', 't': 'all'}\n",
    "]\n",
    "\n",
    "posts_collected = {}\n",
    "\n",
    "\n",
    "for config in scrape_configs:\n",
    "    sort_type = config['sort']\n",
    "    time_filter = config['t']\n",
    "    url = f\"https://old.reddit.com/r/AmItheAsshole/{sort_type}.json\"\n",
    "    \n",
    "    after_token = None\n",
    "    \n",
    "    for i in range(15): \n",
    "        current_agent = random.choice(user_agents)\n",
    "        headers = {'User-Agent': current_agent}\n",
    "        params = {'limit': 100, 't': time_filter, 'after': after_token}\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            \n",
    "            data = response.json()\n",
    "            children = data['data']['children']\n",
    "            \n",
    "            if not children:\n",
    "                break\n",
    "                \n",
    "            for post in children:\n",
    "                p = post['data']\n",
    "                pid = p.get('id')\n",
    "                flair = p.get('link_flair_text')\n",
    "                \n",
    "                valid_flairs = [\"Not the A-hole\", \"Asshole\", \"Everyone Sucks\", \"No A-holes here\"]\n",
    "                \n",
    "                if flair in valid_flairs:\n",
    "                    full_text = f\"{p.get('title')} {p.get('selftext')}\"\n",
    "                    \n",
    "                    if \"[removed]\" not in full_text and \"[deleted]\" not in full_text and len(full_text) > 50:\n",
    "                        posts_collected[pid] = {\n",
    "                            \"text\": full_text,\n",
    "                            \"label\": flair,\n",
    "                            \"id\": pid\n",
    "                        }\n",
    "            \n",
    "            after_token = data['data']['after']\n",
    "            if not after_token:\n",
    "                break\n",
    "            \n",
    "            time.sleep(random.uniform(2, 5))\n",
    "            \n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "df = pd.DataFrame(list(posts_collected.values()))\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df.to_csv(\"aita_clean_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a59135-2bb1-4726-8e52-670717953907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.5694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.72        79\n",
      "           1       0.80      0.06      0.11        65\n",
      "\n",
      "    accuracy                           0.57       144\n",
      "   macro avg       0.68      0.52      0.41       144\n",
      "weighted avg       0.67      0.57      0.44       144\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.6111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65        79\n",
      "           1       0.57      0.54      0.56        65\n",
      "\n",
      "    accuracy                           0.61       144\n",
      "   macro avg       0.61      0.60      0.60       144\n",
      "weighted avg       0.61      0.61      0.61       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"aita_clean_dataset.csv\")\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df = df[df['label'] != \"No A-holes here\"]\n",
    "\n",
    "binary_map = {\n",
    "    \"Not the A-hole\": 0,\n",
    "    \"Asshole\": 1,\n",
    "    \"Everyone Sucks\": 1 \n",
    "}\n",
    "df['label_id'] = df['label'].map(binary_map)\n",
    "df = df.dropna(subset=['label_id'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], \n",
    "    df['label_id'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['label_id']\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "nb_pred = nb.predict(X_test_vec)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_pred):.4f}\")\n",
    "print(classification_report(y_test, nb_pred))\n",
    "\n",
    "print(\"\\nLogistic Regression\")\n",
    "lr = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "lr.fit(X_train_vec, y_train)\n",
    "lr_pred = lr.predict(X_test_vec)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred):.4f}\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba10eb2b-a024-49ae-a7cb-fa273fd93085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d876e84e6046deb2604ee38033a46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5449a00ef3a742f090a50fe420e3491e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [288/288 01:41, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.675220</td>\n",
       "      <td>0.548611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.609571</td>\n",
       "      <td>0.673611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.631327</td>\n",
       "      <td>0.680556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spandanuprit/Desktop/JupyterNotebooks/441/441venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Asshole (0)       0.73      0.67      0.70        79\n",
      "    Asshole (1)       0.63      0.69      0.66        65\n",
      "\n",
      "       accuracy                           0.68       144\n",
      "      macro avg       0.68      0.68      0.68       144\n",
      "   weighted avg       0.68      0.68      0.68       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "filename = \"aita_clean_dataset.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df = df[~df['text'].str.contains(r\"\\[removed\\]\", na=False)]\n",
    "df = df[~df['text'].str.contains(r\"\\[deleted\\]\", na=False)]\n",
    "df = df[df['text'].str.len() > 50]\n",
    "\n",
    "df = df[df['label'] != \"No A-holes here\"]\n",
    "\n",
    "binary_map = {\n",
    "    \"Not the A-hole\": 0,\n",
    "    \"Asshole\": 1,\n",
    "    \"Everyone Sucks\": 1 \n",
    "}\n",
    "df['label_id'] = df['label'].map(binary_map)\n",
    "\n",
    "df = df.dropna(subset=['label_id'])\n",
    "df['label_id'] = df['label_id'].astype(int)\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_id'], random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label_id']].rename(columns={'label_id': 'label'}))\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label_id']].rename(columns={'label_id': 'label'}))\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_final',\n",
    "    num_train_epochs=4,              \n",
    "    per_device_train_batch_size=8,   \n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(f\"Final Accuracy: {results['eval_accuracy']:.4f}\")\n",
    "\n",
    "predictions = trainer.predict(val_tokenized)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "target_names = [\"Not Asshole (0)\", \"Asshole (1)\"]\n",
    "print(classification_report(val_tokenized['label'], preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83bca6-6c12-4146-a513-f580a3afe8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (441venv)",
   "language": "python",
   "name": "441venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
